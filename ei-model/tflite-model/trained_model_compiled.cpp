/* Generated by Edge Impulse
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */
// Generated on: 06.10.2022 16:01:47

#include <stdio.h>
#include <stdlib.h>
#include "edge-impulse-sdk/tensorflow/lite/c/builtin_op_data.h"
#include "edge-impulse-sdk/tensorflow/lite/c/common.h"
#include "edge-impulse-sdk/tensorflow/lite/micro/micro_mutable_op_resolver.h"
#include "edge-impulse-sdk/porting/ei_classifier_porting.h"

#if EI_CLASSIFIER_PRINT_STATE
#if defined(__cplusplus) && EI_C_LINKAGE == 1
extern "C" {
    extern void ei_printf(const char *format, ...);
}
#else
extern void ei_printf(const char *format, ...);
#endif
#endif

#if defined __GNUC__
#define ALIGN(X) __attribute__((aligned(X)))
#elif defined _MSC_VER
#define ALIGN(X) __declspec(align(X))
#elif defined __TASKING__
#define ALIGN(X) __align(X)
#endif

#ifndef EI_MAX_SCRATCH_BUFFER_COUNT
#define EI_MAX_SCRATCH_BUFFER_COUNT 4
#endif // EI_MAX_SCRATCH_BUFFER_COUNT

#ifndef EI_MAX_OVERFLOW_BUFFER_COUNT
#define EI_MAX_OVERFLOW_BUFFER_COUNT 10
#endif // EI_MAX_OVERFLOW_BUFFER_COUNT

using namespace tflite;
using namespace tflite::ops;
using namespace tflite::ops::micro;

namespace {

constexpr int kTensorArenaSize = 14288;

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX)
#pragma Bss(".tensor_arena")
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#pragma Bss()
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16) __attribute__((section(".tensor_arena")));
#else
#define EI_CLASSIFIER_ALLOCATION_HEAP 1
uint8_t* tensor_arena = NULL;
#endif

static uint8_t* tensor_boundary;
static uint8_t* current_location;

template <int SZ, class T> struct TfArray {
  int sz; T elem[SZ];
};
enum used_operators_e {
  OP_RESHAPE, OP_CONV_2D, OP_MAX_POOL_2D, OP_FULLY_CONNECTED, OP_SOFTMAX,  OP_LAST
};
struct TensorInfo_t { // subset of TfLiteTensor used for initialization from constant memory
  TfLiteAllocationType allocation_type;
  TfLiteType type;
  void* data;
  TfLiteIntArray* dims;
  size_t bytes;
  TfLiteQuantization quantization;
};
struct NodeInfo_t { // subset of TfLiteNode used for initialization from constant memory
  struct TfLiteIntArray* inputs;
  struct TfLiteIntArray* outputs;
  void* builtin_data;
  used_operators_e used_op_index;
};

TfLiteContext ctx{};
TfLiteTensor tflTensors[23];
TfLiteEvalTensor tflEvalTensors[23];
TfLiteRegistration registrations[OP_LAST];
TfLiteNode tflNodes[11];

const TfArray<2, int> tensor_dimension0 = { 2, { 1,6435 } };
const TfArray<1, float> quant0_scale = { 1, { 0.0039215688593685627, } };
const TfArray<1, int> quant0_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant0 = { (TfLiteFloatArray*)&quant0_scale, (TfLiteIntArray*)&quant0_zero, 0 };
const ALIGN(16) int32_t tensor_data1[4] = { 1, 1, 99, 65, };
const TfArray<1, int> tensor_dimension1 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data2[4] = { 1, 99, 1, 8, };
const TfArray<1, int> tensor_dimension2 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data3[4] = { 1, 1, 50, 8, };
const TfArray<1, int> tensor_dimension3 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data4[4] = { 1, 50, 1, 16, };
const TfArray<1, int> tensor_dimension4 = { 1, { 4 } };
const ALIGN(8) int32_t tensor_data5[2] = { -1, 400, };
const TfArray<1, int> tensor_dimension5 = { 1, { 2 } };
const ALIGN(16) int8_t tensor_data6[8*1*3*65] = { 
  /* [0][0][][] */ -100,9,-95,49,53,-73,28,47,46,-79,-32,49,-25,76,-44,-106,-48,-32,-60,-62,-104,30,-31,15,77,69,-119,-19,-17,-75,-90,-19,-85,-45,65,20,-127,-85,-21,-118,72,-7,76,-71,-27,46,51,-109,-4,-48,66,-33,-66,-62,-46,72,-45,-64,4,-36,-77,-63,44,-60,-38, -109,-109,-43,27,14,-55,68,87,-16,-62,-83,-49,-8,-62,-40,11,-41,-21,45,75,19,50,10,-56,-79,-46,-37,-3,32,-33,7,-107,-103,-77,76,50,28,6,-101,3,46,-93,-80,-52,64,-110,-50,24,-25,-67,-20,58,30,55,-56,-72,-96,73,19,20,30,-123,67,-112,-47, -88,12,-10,-70,-72,24,-25,-35,-13,74,5,-86,-94,-49,32,8,84,31,52,68,31,3,-16,45,-35,-28,-27,-11,-39,-21,-65,117,-7,20,90,57,-79,11,-46,114,19,-5,-14,-76,-62,73,60,-16,17,-54,16,74,92,48,6,-14,-58,48,56,52,76,29,60,47,58, 
  /* [1][0][][] */ 24,-22,-33,-49,-2,-9,9,-51,-12,36,9,-59,60,39,-2,48,3,21,45,21,2,57,-3,-23,44,28,3,33,0,102,-25,-113,10,-27,-29,-38,-2,-25,-15,13,-9,5,-43,-5,-51,41,35,-47,37,20,-41,4,-95,-98,-59,-79,-28,-20,-65,-59,-44,-5,-11,-56,-44, 10,-33,-51,-39,-7,-40,58,47,14,-46,45,-71,35,75,72,-58,5,17,70,62,-4,24,-31,59,34,-18,-5,75,49,7,43,-67,-47,-15,-65,-35,-59,-65,-12,-19,18,-7,-95,-1,-48,-48,12,47,17,-23,-31,-3,-1,-19,-58,-40,-49,-45,-41,25,-26,-84,-101,-95,-127, -62,-55,-21,-43,-27,60,56,66,46,43,-57,-56,2,-6,76,10,54,42,24,12,111,-3,72,36,4,-37,67,70,35,34,-24,2,60,22,42,25,48,-40,4,27,40,30,-40,-78,50,-55,7,45,-32,-52,-41,-61,-108,-117,-12,18,-3,-24,-105,-74,-91,-7,-99,-12,-49, 
  /* [2][0][][] */ 26,-21,-18,24,-50,-43,-44,22,-7,-10,6,46,51,51,16,-12,33,20,17,60,15,24,-5,18,-30,-27,-9,-22,-7,14,-69,-95,-19,-61,-40,8,-31,-34,-12,-16,-28,-47,-41,2,-29,18,-15,-39,-31,-38,-21,-54,-31,-54,-22,-53,-15,-60,-66,-18,-57,-51,-66,-62,-74, 30,-7,39,4,-14,-20,7,2,0,13,-22,42,40,13,19,-24,-27,43,14,46,0,39,25,-13,-51,-8,-34,13,33,9,-79,-115,-37,-46,-50,3,-41,-40,-27,-56,-21,5,-29,-53,-61,-31,-7,19,-28,-36,-18,-51,-92,-24,-73,-4,-54,-18,-34,-35,-1,-8,-41,-52,-68, 30,-7,-8,-13,3,20,15,8,32,-5,31,12,28,45,28,31,-17,-19,36,55,51,-12,4,-12,10,-53,5,47,4,7,-30,-127,-16,-57,-32,-27,19,-29,-32,10,24,-48,-61,-28,-40,17,-25,1,7,-30,-47,-64,-51,-30,-30,-39,-19,0,-62,-17,-51,-47,-54,-42,-62, 
  /* [3][0][][] */ -42,53,-20,76,85,-44,1,45,-18,35,4,-24,-34,9,-2,-89,-40,-33,-116,-93,-63,5,38,-47,57,10,-25,-52,-78,-35,-4,52,-12,-46,-26,2,-47,48,-3,-62,-48,14,22,-43,51,46,37,-7,-27,30,-50,36,8,-28,-7,77,1,69,-10,-73,-9,46,47,-8,26, 17,4,-10,38,51,60,-31,-48,27,6,-5,-65,-102,-1,-86,-36,-78,29,-83,-14,-89,14,4,12,-8,41,59,43,-17,-15,-44,109,43,5,63,3,-33,-52,-39,-34,-9,-41,68,-24,-6,-59,-60,-50,43,49,69,-26,20,107,88,44,9,-5,9,25,82,5,76,79,81, -14,47,-27,70,46,-51,66,-18,5,41,23,29,15,15,-73,6,-99,-21,-79,-106,-127,-43,2,40,-14,-3,50,-6,15,-72,-32,60,-47,2,38,-8,36,49,-33,-59,-89,40,29,-25,-29,11,-42,16,49,-14,17,21,37,97,-6,11,-14,-43,41,40,-45,-53,44,44,8, 
  /* [4][0][][] */ 24,61,-46,46,76,-54,0,-5,-81,18,15,73,12,23,-7,-72,-4,-62,-30,-68,-51,-57,-17,-82,25,22,-21,-74,10,-127,-52,-49,29,-86,-90,-58,59,57,-53,21,-84,32,3,22,33,-18,-116,-101,-28,-48,38,-64,-43,26,-58,-22,49,-51,-40,21,-25,-50,-33,112,65, 78,-21,25,34,18,58,41,-40,-4,52,5,73,-44,23,1,-25,-17,64,20,34,-83,-72,-43,13,31,56,-35,23,-7,-77,-51,-25,-19,-11,16,42,-1,91,-9,99,-21,30,69,85,-14,-66,12,19,46,42,93,95,77,86,90,58,15,57,71,33,73,25,107,-4,117, 34,-3,63,-36,40,51,45,-2,-2,8,48,79,-15,19,-5,12,20,-18,8,-62,-103,-81,-38,35,-7,-19,7,-55,29,17,30,-11,-61,29,-56,-10,41,1,-10,20,-49,45,-32,-72,51,-50,-70,-91,-46,-68,16,11,25,109,-14,-3,-56,68,58,-108,33,-13,48,69,26, 
  /* [5][0][][] */ 79,3,-25,-6,-5,-36,-59,-40,31,-73,-57,-44,12,-59,-81,-24,-27,10,-82,3,-54,32,38,-26,9,-32,68,-34,-25,2,46,35,-74,-23,-29,58,16,-42,-29,-39,-52,-25,-41,77,16,21,30,47,-14,53,-3,-31,-10,-9,-13,10,55,-27,83,-65,-39,-76,-64,-16,23, 58,43,12,-41,68,29,52,-22,26,48,-9,-127,22,-19,-23,-42,-17,-63,-90,-28,-67,24,61,62,-30,0,92,49,52,-19,58,28,-53,46,9,-17,-44,2,-26,36,73,69,30,58,84,-18,-10,-85,-52,78,-42,-7,38,31,88,17,12,-46,77,-83,-20,-50,70,92,88, 12,1,-45,62,69,8,50,-24,-71,-56,-13,-45,27,-67,-49,20,-121,-86,-18,-116,-73,-27,4,-40,3,70,79,56,-50,47,4,39,-10,58,-19,50,25,-66,-32,-13,30,-33,5,59,28,-70,91,19,-43,55,-31,18,-19,33,-68,-29,78,15,1,47,-5,-3,-79,66,-40, 
  /* [6][0][][] */ -28,-1,-31,-28,7,-16,51,17,-56,60,-21,54,12,-36,16,6,11,-33,-13,-75,-75,-20,-12,47,0,-45,-55,-24,33,-94,-118,-85,-46,18,-20,57,8,-53,-13,83,-19,-40,30,79,11,21,-60,-85,-7,-36,43,26,39,45,-43,70,-29,28,-53,43,36,44,74,81,19, -4,-5,-4,57,7,18,-39,-52,-56,-5,35,38,63,-17,25,-52,28,17,-17,-12,-57,44,22,21,54,33,20,-17,-17,-38,-20,-74,-63,-32,42,55,14,22,49,-33,-50,104,53,127,-2,15,-16,15,70,73,109,89,10,104,85,67,96,10,-40,21,115,-25,52,58,25, 62,77,-15,16,-11,-52,-18,30,-40,-39,-36,0,17,45,26,-6,23,37,40,-8,-19,-78,-74,18,5,29,-12,7,-78,-88,-55,-95,-71,-48,19,14,60,24,3,85,-9,-31,118,21,70,-45,54,29,16,-19,44,87,111,28,-14,-1,4,82,-4,-34,64,88,11,9,14, 
  /* [7][0][][] */ -2,-33,-33,38,45,-37,1,41,-13,29,-45,-22,-13,16,-21,-26,-63,-23,12,-81,-9,-30,39,51,83,64,-23,-75,16,-4,-31,61,12,-30,0,-13,47,-30,38,21,-10,2,5,32,-23,0,33,-10,34,-9,4,24,-7,27,58,-70,29,22,-2,-73,11,-33,62,33,113, 39,40,-25,46,62,30,11,41,29,-41,-58,-71,-1,-24,-72,-73,-75,-79,-91,-13,-61,8,23,-22,43,-20,-4,-31,-5,-62,47,72,6,-20,28,26,36,7,11,-16,14,53,52,-25,19,-43,-8,-52,-23,9,60,-29,-19,61,68,27,6,66,-11,-70,77,32,13,38,114, -10,-6,42,55,-1,35,20,-15,-31,10,-8,-34,-52,-28,-78,-51,-44,-73,-34,-83,-77,-3,-46,-7,-7,42,-30,2,-39,-87,-36,101,38,44,51,36,-48,-43,-18,24,15,-20,22,37,-20,-25,45,-43,-25,-25,14,56,14,105,4,39,-18,-13,30,8,41,15,43,113,127, 
};
const TfArray<4, int> tensor_dimension6 = { 4, { 8,1,3,65 } };
const TfArray<8, float> quant6_scale = { 8, { 0.001584220677614212, 0.0025560690555721521, 0.0043271486647427082, 0.0026465931441634893, 0.0023246840573847294, 0.0022588053252547979, 0.0024790023453533649, 0.0032447006087750196, } };
const TfArray<8, int> quant6_zero = { 8, { 0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant6 = { (TfLiteFloatArray*)&quant6_scale, (TfLiteIntArray*)&quant6_zero, 0 };
const ALIGN(16) int32_t tensor_data7[8] = { -3699, 8757, 9966, -986, -1911, 9291, -3224, -1447, };
const TfArray<1, int> tensor_dimension7 = { 1, { 8 } };
const TfArray<8, float> quant7_scale = { 8, { 6.2126305238052737e-06, 1.0023801223724149e-05, 1.6969212083495222e-05, 1.0378797014709562e-05, 9.1164083642070182e-06, 8.8580609372002073e-06, 9.7215779533144087e-06, 1.2724316547974013e-05, } };
const TfArray<8, int> quant7_zero = { 8, { 0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant7 = { (TfLiteFloatArray*)&quant7_scale, (TfLiteIntArray*)&quant7_zero, 0 };
const ALIGN(16) int8_t tensor_data8[16*1*3*8] = { 
  /* [0][0][][] */ -69,-52,-76,127,-14,-46,80,52, 78,-31,-117,11,11,-65,32,58, 69,-70,-1,112,56,99,50,73, 
  /* [1][0][][] */ -59,64,-127,-44,30,-33,55,73, -83,-68,-103,30,-16,29,-23,20, 59,63,-35,105,97,-37,-50,44, 
  /* [2][0][][] */ -59,58,-127,-12,50,71,-41,-52, 59,-18,-106,123,66,-32,-40,96, -14,-53,-99,-34,54,25,43,70, 
  /* [3][0][][] */ -70,-7,-71,25,-49,74,-50,127, -42,-31,-33,116,86,60,41,4, 5,-94,-26,43,-28,64,41,-24, 
  /* [4][0][][] */ 18,29,110,8,28,-41,-14,54, -63,-26,26,10,-25,-21,35,90, 75,-49,62,85,-35,75,-29,127, 
  /* [5][0][][] */ 54,-38,-127,64,76,80,8,126, -38,-47,-103,67,42,76,-41,-15, -16,5,-25,37,36,5,-47,113, 
  /* [6][0][][] */ 60,42,127,33,-9,26,-54,14, 34,34,115,-70,-12,68,-27,-90, -40,78,75,-46,10,-36,-20,-59, 
  /* [7][0][][] */ -58,-67,4,23,-11,92,98,107, 27,-80,-97,54,103,68,88,-11, -66,-81,-105,49,50,36,-12,127, 
  /* [8][0][][] */ -61,-41,3,-4,-2,7,21,110, -18,-42,-81,107,93,34,80,109, 8,-75,-5,-23,30,-26,127,115, 
  /* [9][0][][] */ -21,-13,91,-33,16,41,-83,-53, -13,97,127,-75,-7,26,33,-70, -49,20,116,-24,-3,-13,21,-18, 
  /* [10][0][][] */ -10,-6,9,5,37,-105,2,-30, 58,-16,-14,34,127,6,124,-83, 3,-22,-42,-55,28,-29,103,-7, 
  /* [11][0][][] */ 4,-11,51,2,-22,-68,32,-53, -13,101,127,-66,-57,-25,-4,-2, 22,42,2,17,67,-68,66,-33, 
  /* [12][0][][] */ 59,-6,-106,-7,73,55,55,-31, -39,-45,40,13,95,-75,77,90, -7,1,-84,-26,-23,44,27,127, 
  /* [13][0][][] */ -32,79,17,16,-78,-86,-10,-109, -65,-1,125,-74,65,1,-44,-107, -25,-90,59,10,23,27,127,-63, 
  /* [14][0][][] */ 13,38,110,9,-73,77,-46,-74, 29,46,11,-19,35,-9,-15,-54, -35,84,127,-68,-25,31,-15,-39, 
  /* [15][0][][] */ 70,59,82,14,-59,-57,-77,-36, -10,55,84,-91,35,57,60,-22, 58,-9,127,-83,-41,30,-59,-16, 
};
const TfArray<4, int> tensor_dimension8 = { 4, { 16,1,3,8 } };
const TfArray<16, float> quant8_scale = { 16, { 0.0029562623240053654, 0.0032198128756135702, 0.0032685599289834499, 0.0027568966615945101, 0.0039427685551345348, 0.0038815008010715246, 0.0040635345503687859, 0.0033129318617284298, 0.0037072158884257078, 0.0044333720579743385, 0.0040576029568910599, 0.0039364309050142765, 0.0030850567854940891, 0.0028494426514953375, 0.0040863044559955597, 0.003849714994430542, } };
const TfArray<16, int> quant8_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant8 = { (TfLiteFloatArray*)&quant8_scale, (TfLiteIntArray*)&quant8_zero, 0 };
const ALIGN(16) int32_t tensor_data9[16] = { 2657, 763, 1182, -2844, 1265, 948, 4663, -214, 592, 4605, -172, 4017, -1307, 7898, 4364, 6383, };
const TfArray<1, int> tensor_dimension9 = { 1, { 16 } };
const TfArray<16, float> quant9_scale = { 16, { 2.1960593585390598e-05, 2.3918377337395214e-05, 2.4280496290884912e-05, 2.0479605154832825e-05, 2.9288854420883581e-05, 2.8833726901211776e-05, 3.0185963623807766e-05, 2.461011172272265e-05, 2.7539050279301591e-05, 3.2933301554294303e-05, 3.0141900424496271e-05, 2.9241775337141007e-05, 2.291734199388884e-05, 2.1167083104955964e-05, 3.0355109629454091e-05, 2.8597605705726892e-05, } };
const TfArray<16, int> quant9_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant9 = { (TfLiteFloatArray*)&quant9_scale, (TfLiteIntArray*)&quant9_zero, 0 };
const ALIGN(16) int8_t tensor_data10[2*400] = { 
  -24, -72, -50, -39, 16, -60, 55, -5, -29, 53, -34, 38, -51, 4, 27, 22, -13, -33, 3, -25, 46, 24, 25, 18, 13, 7, 56, -28, 39, 61, 46, 91, 1, 0, -61, -36, 64, -51, 101, 12, -44, 47, -64, 31, -25, -37, 80, 87, -14, -81, -18, 2, 91, 13, 24, -16, -25, -5, -24, 19, -9, -25, 49, 115, -57, -50, -33, -53, 43, -43, 59, -15, -91, 8, -124, -36, -36, -28, 39, 43, -58, -54, -23, -26, -24, -42, 56, -71, -37, 24, -125, -37, -93, 18, 21, 84, 2, -27, -18, -15, 48, -72, 66, -35, 22, 39, 11, 42, -47, 18, -11, 54, 31, -42, -58, 0, 11, -56, 6, -26, 25, 22, -5, 45, -15, 29, 60, 97, 4, -60, 0, 9, 40, -5, 41, 36, 56, 28, 84, 23, 43, 38, 55, 63, -23, -58, -6, 11, 37, -24, 7, 17, 20, 16, 37, 67, -2, 32, 63, 41, -19, -50, -18, 3, 6, -47, -9, 31, -29, 24, 28, 9, -16, 64, 69, 36, 3, 10, -39, 5, 24, -35, 74, -20, -47, 56, -57, 14, -25, -51, 28, 61, -35, -56, -30, -27, 32, -8, 54, -2, 54, 31, 31, 45, 7, 28, 6, 72, 55, -21, 18, 20, -32, -37, 12, 35, 26, 28, 41, -40, 32, 42, 15, 67, 62, -56, -9, -5, 40, 4, 26, 9, 30, 75, -1, 6, 5, 0, 27, 74, -27, -33, -59, 19, -1, 8, 4, -26, -50, 53, -7, -45, -14, 39, 38, 16, 10, -67, -31, 20, -29, 17, 53, -56, -98, 53, -72, -14, -38, -41, 84, 32, -46, 3, -44, -21, -78, -2, 74, -13, -110, 61, -41, 16, -51, 5, 39, 61, -61, 3, -4, 6, -43, -23, 9, -45, -28, 69, 54, 19, -26, -36, 9, 80, -81, 8, -71, -46, -52, -56, 71, -44, -60, 40, -7, 51, 8, 66, -3, 48, -47, 35, -39, -27, 9, -72, 8, -10, -13, 30, 47, 57, -32, 92, 3, 25, -79, -21, -54, 28, -60, -2, 52, -3, -68, 22, 32, 73, -14, -37, 54, 109, -32, 4, -2, -65, -47, -66, 14, -43, -50, 72, 76, 86, -45, 59, 60, 92, -2, -54, -6, 1, -16, -43, 78, -56, -5, 15, 46, 41, 28, 41, 73, 68, -42, 13, -26, -34, 13, -11, 47, -63, -29, 42, 76, 106, 28, 127, 17, 78, 
  36, -8, 42, 36, 20, 54, -17, 30, 39, -38, 36, -25, 49, -1, -43, -66, 44, 4, 46, 31, -67, -10, -49, -31, -73, -31, 19, 1, -30, -41, -32, -40, -6, 8, 69, 0, -61, 5, -72, -27, -2, -14, 81, 24, -1, -5, -49, -66, 45, 84, 45, 34, -87, -14, -39, 56, 50, -51, 70, -23, 11, -38, -44, -90, 33, 73, 18, -29, -50, 6, -26, 46, 86, -73, 91, 40, 14, 49, -75, -60, 22, 69, 71, -8, -3, 17, -3, 49, -1, -80, 119, -22, 76, 0, -14, -81, 24, 75, 87, 24, -52, 69, -7, 32, 18, -27, -13, -34, -5, -38, 24, -54, -13, 14, 65, -7, -40, -9, -5, 49, 12, -18, 18, -8, -2, -53, -41, -102, -9, 58, 13, 35, -16, -17, -45, -11, 9, -28, -38, 2, -46, 8, -54, -64, 31, 18, 39, 48, 1, 8, -10, -41, 27, 2, 8, -54, 28, -48, -33, -104, 17, 81, 69, 26, 17, 34, 6, 17, -41, -77, 18, -33, -50, -36, -1, -73, 36, 29, 43, 28, -88, 15, -30, 24, -28, 2, 61, 15, 15, 66, -54, -61, 36, 59, -5, -16, 27, -15, -45, -14, 4, -61, -18, -18, 14, -24, -1, -37, 4, -10, 23, -31, 14, -4, -6, -25, -95, -8, -60, 15, -10, -54, -44, -66, -36, 51, 42, 43, 32, 49, -13, -38, -23, -23, -7, -32, 6, -66, 22, -32, -12, 45, 83, 30, -35, -4, -55, 23, 49, 2, 27, 1, 19, -32, -23, -37, 59, 79, 90, 6, 10, 59, -13, 38, 68, -46, 3, -9, 48, 10, -37, -30, 57, -3, -22, 12, 11, -5, -32, 17, 56, -74, 65, -39, 36, -35, -35, -70, 75, -7, 22, 4, -14, -5, -43, 64, -16, -53, 26, -4, 34, -22, -15, -16, 16, 12, 62, -4, 29, 36, -1, 20, 41, -76, 41, -59, 62, -60, -79, -35, 23, 43, 24, 8, 15, 74, -62, 51, -25, -54, -60, -92, 30, -38, -59, -35, 75, -17, 35, 19, 31, 33, -62, 41, 41, -68, 15, 9, 14, -24, -89, -121, 87, 62, 28, 16, 24, 64, -35, 41, 29, -68, -36, -53, 0, -39, -24, -94, 59, -25, -2, -23, 9, 30, -64, 55, 20, -52, -54, -31, -23, -97, -5, -46, 48, -8, 60, 41, 6, 72, -49, 52, 97, -58, -61, -60, 40, -109, -7, -23, 
};
const TfArray<2, int> tensor_dimension10 = { 2, { 2,400 } };
const TfArray<1, float> quant10_scale = { 1, { 0.0028690968174487352, } };
const TfArray<1, int> quant10_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant10 = { (TfLiteFloatArray*)&quant10_scale, (TfLiteIntArray*)&quant10_zero, 0 };
const ALIGN(8) int32_t tensor_data11[2] = { 4511, -4511, };
const TfArray<1, int> tensor_dimension11 = { 1, { 2 } };
const TfArray<1, float> quant11_scale = { 1, { 2.7816649890155531e-05, } };
const TfArray<1, int> quant11_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant11 = { (TfLiteFloatArray*)&quant11_scale, (TfLiteIntArray*)&quant11_zero, 0 };
const TfArray<4, int> tensor_dimension12 = { 4, { 1,1,99,65 } };
const TfArray<1, float> quant12_scale = { 1, { 0.0039215688593685627, } };
const TfArray<1, int> quant12_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant12 = { (TfLiteFloatArray*)&quant12_scale, (TfLiteIntArray*)&quant12_zero, 0 };
const TfArray<4, int> tensor_dimension13 = { 4, { 1,1,99,8 } };
const TfArray<1, float> quant13_scale = { 1, { 0.0074284994043409824, } };
const TfArray<1, int> quant13_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant13 = { (TfLiteFloatArray*)&quant13_scale, (TfLiteIntArray*)&quant13_zero, 0 };
const TfArray<4, int> tensor_dimension14 = { 4, { 1,99,1,8 } };
const TfArray<1, float> quant14_scale = { 1, { 0.0074284994043409824, } };
const TfArray<1, int> quant14_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant14 = { (TfLiteFloatArray*)&quant14_scale, (TfLiteIntArray*)&quant14_zero, 0 };
const TfArray<4, int> tensor_dimension15 = { 4, { 1,50,1,8 } };
const TfArray<1, float> quant15_scale = { 1, { 0.0074284994043409824, } };
const TfArray<1, int> quant15_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant15 = { (TfLiteFloatArray*)&quant15_scale, (TfLiteIntArray*)&quant15_zero, 0 };
const TfArray<4, int> tensor_dimension16 = { 4, { 1,1,50,8 } };
const TfArray<1, float> quant16_scale = { 1, { 0.0074284994043409824, } };
const TfArray<1, int> quant16_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant16 = { (TfLiteFloatArray*)&quant16_scale, (TfLiteIntArray*)&quant16_zero, 0 };
const TfArray<4, int> tensor_dimension17 = { 4, { 1,1,50,16 } };
const TfArray<1, float> quant17_scale = { 1, { 0.0096952635794878006, } };
const TfArray<1, int> quant17_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant17 = { (TfLiteFloatArray*)&quant17_scale, (TfLiteIntArray*)&quant17_zero, 0 };
const TfArray<4, int> tensor_dimension18 = { 4, { 1,50,1,16 } };
const TfArray<1, float> quant18_scale = { 1, { 0.0096952635794878006, } };
const TfArray<1, int> quant18_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant18 = { (TfLiteFloatArray*)&quant18_scale, (TfLiteIntArray*)&quant18_zero, 0 };
const TfArray<4, int> tensor_dimension19 = { 4, { 1,25,1,16 } };
const TfArray<1, float> quant19_scale = { 1, { 0.0096952635794878006, } };
const TfArray<1, int> quant19_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant19 = { (TfLiteFloatArray*)&quant19_scale, (TfLiteIntArray*)&quant19_zero, 0 };
const TfArray<2, int> tensor_dimension20 = { 2, { 1,400 } };
const TfArray<1, float> quant20_scale = { 1, { 0.0096952635794878006, } };
const TfArray<1, int> quant20_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant20 = { (TfLiteFloatArray*)&quant20_scale, (TfLiteIntArray*)&quant20_zero, 0 };
const TfArray<2, int> tensor_dimension21 = { 2, { 1,2 } };
const TfArray<1, float> quant21_scale = { 1, { 0.08524341881275177, } };
const TfArray<1, int> quant21_zero = { 1, { -2 } };
const TfLiteAffineQuantization quant21 = { (TfLiteFloatArray*)&quant21_scale, (TfLiteIntArray*)&quant21_zero, 0 };
const TfArray<2, int> tensor_dimension22 = { 2, { 1,2 } };
const TfArray<1, float> quant22_scale = { 1, { 0.00390625, } };
const TfArray<1, int> quant22_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant22 = { (TfLiteFloatArray*)&quant22_scale, (TfLiteIntArray*)&quant22_zero, 0 };
const TfLiteReshapeParams opdata0 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs0 = { 2, { 0,1 } };
const TfArray<1, int> outputs0 = { 1, { 12 } };
const TfLiteConvParams opdata1 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs1 = { 3, { 12,6,7 } };
const TfArray<1, int> outputs1 = { 1, { 13 } };
const TfLiteReshapeParams opdata2 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs2 = { 2, { 13,2 } };
const TfArray<1, int> outputs2 = { 1, { 14 } };
const TfLitePoolParams opdata3 = { kTfLitePaddingSame, 1,2, 1,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs3 = { 1, { 14 } };
const TfArray<1, int> outputs3 = { 1, { 15 } };
const TfLiteReshapeParams opdata4 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs4 = { 2, { 15,3 } };
const TfArray<1, int> outputs4 = { 1, { 16 } };
const TfLiteConvParams opdata5 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs5 = { 3, { 16,8,9 } };
const TfArray<1, int> outputs5 = { 1, { 17 } };
const TfLiteReshapeParams opdata6 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs6 = { 2, { 17,4 } };
const TfArray<1, int> outputs6 = { 1, { 18 } };
const TfLitePoolParams opdata7 = { kTfLitePaddingSame, 1,2, 1,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs7 = { 1, { 18 } };
const TfArray<1, int> outputs7 = { 1, { 19 } };
const TfLiteReshapeParams opdata8 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs8 = { 2, { 19,5 } };
const TfArray<1, int> outputs8 = { 1, { 20 } };
const TfLiteFullyConnectedParams opdata9 = { kTfLiteActNone, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs9 = { 3, { 20,10,11 } };
const TfArray<1, int> outputs9 = { 1, { 21 } };
const TfLiteSoftmaxParams opdata10 = { 1 };
const TfArray<1, int> inputs10 = { 1, { 21 } };
const TfArray<1, int> outputs10 = { 1, { 22 } };
const TensorInfo_t tensorData[] = {
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 6448, (TfLiteIntArray*)&tensor_dimension0, 6435, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant0))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data1, (TfLiteIntArray*)&tensor_dimension1, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data2, (TfLiteIntArray*)&tensor_dimension2, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data3, (TfLiteIntArray*)&tensor_dimension3, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data4, (TfLiteIntArray*)&tensor_dimension4, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data5, (TfLiteIntArray*)&tensor_dimension5, 8, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data6, (TfLiteIntArray*)&tensor_dimension6, 1560, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant6))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data7, (TfLiteIntArray*)&tensor_dimension7, 32, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant7))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data8, (TfLiteIntArray*)&tensor_dimension8, 384, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant8))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data9, (TfLiteIntArray*)&tensor_dimension9, 64, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant9))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data10, (TfLiteIntArray*)&tensor_dimension10, 800, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant10))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data11, (TfLiteIntArray*)&tensor_dimension11, 8, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant11))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension12, 6435, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant12))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 6448, (TfLiteIntArray*)&tensor_dimension13, 792, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant13))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension14, 792, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant14))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 800, (TfLiteIntArray*)&tensor_dimension15, 400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant15))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension16, 400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant16))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 800, (TfLiteIntArray*)&tensor_dimension17, 800, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant17))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension18, 800, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant18))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 800, (TfLiteIntArray*)&tensor_dimension19, 400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant19))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension20, 400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant20))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 400, (TfLiteIntArray*)&tensor_dimension21, 2, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant21))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension22, 2, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant22))}, },
};const NodeInfo_t nodeData[] = {
  { (TfLiteIntArray*)&inputs0, (TfLiteIntArray*)&outputs0, const_cast<void*>(static_cast<const void*>(&opdata0)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs1, (TfLiteIntArray*)&outputs1, const_cast<void*>(static_cast<const void*>(&opdata1)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs2, (TfLiteIntArray*)&outputs2, const_cast<void*>(static_cast<const void*>(&opdata2)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs3, (TfLiteIntArray*)&outputs3, const_cast<void*>(static_cast<const void*>(&opdata3)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs4, (TfLiteIntArray*)&outputs4, const_cast<void*>(static_cast<const void*>(&opdata4)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs5, (TfLiteIntArray*)&outputs5, const_cast<void*>(static_cast<const void*>(&opdata5)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs6, (TfLiteIntArray*)&outputs6, const_cast<void*>(static_cast<const void*>(&opdata6)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs7, (TfLiteIntArray*)&outputs7, const_cast<void*>(static_cast<const void*>(&opdata7)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs8, (TfLiteIntArray*)&outputs8, const_cast<void*>(static_cast<const void*>(&opdata8)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs9, (TfLiteIntArray*)&outputs9, const_cast<void*>(static_cast<const void*>(&opdata9)), OP_FULLY_CONNECTED, },
  { (TfLiteIntArray*)&inputs10, (TfLiteIntArray*)&outputs10, const_cast<void*>(static_cast<const void*>(&opdata10)), OP_SOFTMAX, },
};
static void* overflow_buffers[EI_MAX_OVERFLOW_BUFFER_COUNT];
static size_t overflow_buffers_ix = 0;
static void * AllocatePersistentBuffer(struct TfLiteContext* ctx,
                                       size_t bytes) {
  void *ptr;
  if (current_location - bytes < tensor_boundary) {
    if (overflow_buffers_ix > EI_MAX_OVERFLOW_BUFFER_COUNT - 1) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d, does not fit in tensor arena and reached EI_MAX_OVERFLOW_BUFFER_COUNT\n",
        (int)bytes);
      return NULL;
    }

    // OK, this will look super weird, but.... we have CMSIS-NN buffers which
    // we cannot calculate beforehand easily.
    ptr = ei_calloc(bytes, 1);
    if (ptr == NULL) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d\n", (int)bytes);
      return NULL;
    }
    overflow_buffers[overflow_buffers_ix++] = ptr;
    return ptr;
  }

  current_location -= bytes;

  ptr = current_location;
  memset(ptr, 0, bytes);

  return ptr;
}
typedef struct {
  size_t bytes;
  void *ptr;
} scratch_buffer_t;
static scratch_buffer_t scratch_buffers[EI_MAX_SCRATCH_BUFFER_COUNT];
static size_t scratch_buffers_ix = 0;

static TfLiteStatus RequestScratchBufferInArena(struct TfLiteContext* ctx, size_t bytes,
                                                int* buffer_idx) {
  if (scratch_buffers_ix > EI_MAX_SCRATCH_BUFFER_COUNT - 1) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d, reached EI_MAX_SCRATCH_BUFFER_COUNT\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffer_t b;
  b.bytes = bytes;

  b.ptr = AllocatePersistentBuffer(ctx, b.bytes);
  if (!b.ptr) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffers[scratch_buffers_ix] = b;
  *buffer_idx = scratch_buffers_ix;

  scratch_buffers_ix++;

  return kTfLiteOk;
}

static void* GetScratchBuffer(struct TfLiteContext* ctx, int buffer_idx) {
  if (buffer_idx > (int)scratch_buffers_ix) {
    return NULL;
  }
  return scratch_buffers[buffer_idx].ptr;
}

static TfLiteTensor* GetTensor(const struct TfLiteContext* context,
                               int tensor_idx) {
  return &tflTensors[tensor_idx];
}

static TfLiteEvalTensor* GetEvalTensor(const struct TfLiteContext* context,
                                       int tensor_idx) {
  return &tflEvalTensors[tensor_idx];
}

} // namespace

TfLiteStatus trained_model_init( void*(*alloc_fnc)(size_t,size_t) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  tensor_arena = (uint8_t*) alloc_fnc(16, kTensorArenaSize);
  if (!tensor_arena) {
    ei_printf("ERR: failed to allocate tensor arena\n");
    return kTfLiteError;
  }
#else
  memset(tensor_arena, 0, kTensorArenaSize);
#endif
  tensor_boundary = tensor_arena;
  current_location = tensor_arena + kTensorArenaSize;
  ctx.AllocatePersistentBuffer = &AllocatePersistentBuffer;
  ctx.RequestScratchBufferInArena = &RequestScratchBufferInArena;
  ctx.GetScratchBuffer = &GetScratchBuffer;
  ctx.GetTensor = &GetTensor;
  ctx.GetEvalTensor = &GetEvalTensor;
  ctx.tensors = tflTensors;
  ctx.tensors_size = 23;
  for (size_t i = 0; i < 23; ++i) {
    tflTensors[i].type = tensorData[i].type;
    tflEvalTensors[i].type = tensorData[i].type;
    tflTensors[i].is_variable = 0;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
    tflTensors[i].allocation_type = tensorData[i].allocation_type;
#else
    tflTensors[i].allocation_type = (tensor_arena <= tensorData[i].data && tensorData[i].data < tensor_arena + kTensorArenaSize) ? kTfLiteArenaRw : kTfLiteMmapRo;
#endif
    tflTensors[i].bytes = tensorData[i].bytes;
    tflTensors[i].dims = tensorData[i].dims;
    tflEvalTensors[i].dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
    if(tflTensors[i].allocation_type == kTfLiteArenaRw){
      uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

     tflTensors[i].data.data =  start;
     tflEvalTensors[i].data.data =  start;
    }
    else {
       tflTensors[i].data.data = tensorData[i].data;
       tflEvalTensors[i].data.data = tensorData[i].data;
    }
#else
    tflTensors[i].data.data = tensorData[i].data;
    tflEvalTensors[i].data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
    tflTensors[i].quantization = tensorData[i].quantization;
    if (tflTensors[i].quantization.type == kTfLiteAffineQuantization) {
      TfLiteAffineQuantization const* quant = ((TfLiteAffineQuantization const*)(tensorData[i].quantization.params));
      tflTensors[i].params.scale = quant->scale->data[0];
      tflTensors[i].params.zero_point = quant->zero_point->data[0];
    }
    if (tflTensors[i].allocation_type == kTfLiteArenaRw) {
      auto data_end_ptr = (uint8_t*)tflTensors[i].data.data + tensorData[i].bytes;
      if (data_end_ptr > tensor_boundary) {
        tensor_boundary = data_end_ptr;
      }
    }
  }
  if (tensor_boundary > current_location /* end of arena size */) {
    ei_printf("ERR: tensor arena is too small, does not fit model - even without scratch buffers\n");
    return kTfLiteError;
  }
  registrations[OP_RESHAPE] = Register_RESHAPE();
  registrations[OP_CONV_2D] = Register_CONV_2D();
  registrations[OP_MAX_POOL_2D] = Register_MAX_POOL_2D();
  registrations[OP_FULLY_CONNECTED] = Register_FULLY_CONNECTED();
  registrations[OP_SOFTMAX] = Register_SOFTMAX();

  for (size_t i = 0; i < 11; ++i) {
    tflNodes[i].inputs = nodeData[i].inputs;
    tflNodes[i].outputs = nodeData[i].outputs;
    tflNodes[i].builtin_data = nodeData[i].builtin_data;
tflNodes[i].custom_initial_data = nullptr;
      tflNodes[i].custom_initial_data_size = 0;
if (registrations[nodeData[i].used_op_index].init) {
      tflNodes[i].user_data = registrations[nodeData[i].used_op_index].init(&ctx, (const char*)tflNodes[i].builtin_data, 0);
    }
  }
  for (size_t i = 0; i < 11; ++i) {
    if (registrations[nodeData[i].used_op_index].prepare) {
      TfLiteStatus status = registrations[nodeData[i].used_op_index].prepare(&ctx, &tflNodes[i]);
      if (status != kTfLiteOk) {
        return status;
      }
    }
  }
  return kTfLiteOk;
}

static const int inTensorIndices[] = {
  0, 
};
TfLiteTensor* trained_model_input(int index) {
  return &ctx.tensors[inTensorIndices[index]];
}

static const int outTensorIndices[] = {
  22, 
};
TfLiteTensor* trained_model_output(int index) {
  return &ctx.tensors[outTensorIndices[index]];
}

TfLiteStatus trained_model_invoke() {
  for (size_t i = 0; i < 11; ++i) {
    TfLiteStatus status = registrations[nodeData[i].used_op_index].invoke(&ctx, &tflNodes[i]);

#if EI_CLASSIFIER_PRINT_STATE
    ei_printf("layer %lu\n", i);
    ei_printf("    inputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].inputs->size; ix++) {
      auto d = tensorData[tflNodes[i].inputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");

    ei_printf("    outputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].outputs->size; ix++) {
      auto d = tensorData[tflNodes[i].outputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");
#endif // EI_CLASSIFIER_PRINT_STATE

    if (status != kTfLiteOk) {
      return status;
    }
  }
  return kTfLiteOk;
}

TfLiteStatus trained_model_reset( void (*free_fnc)(void* ptr) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  free_fnc(tensor_arena);
#endif

  // scratch buffers are allocated within the arena, so just reset the counter so memory can be reused
  scratch_buffers_ix = 0;

  // overflow buffers are on the heap, so free them first
  for (size_t ix = 0; ix < overflow_buffers_ix; ix++) {
    ei_free(overflow_buffers[ix]);
  }
  overflow_buffers_ix = 0;
  return kTfLiteOk;
}
